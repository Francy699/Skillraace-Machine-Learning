{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7WQD9u44gfKq032g5/HzY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":170,"metadata":{"id":"Cb24quFA8sa_","executionInfo":{"status":"ok","timestamp":1720091181494,"user_tz":-330,"elapsed":795,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#Naive Bayes Classifier\n","A Naive Bayes classifier is a probabilistic machine learning algorithm based on Bayes' theorem. It is particularly useful for classification tasks, especially when dealing with high-dimensional data.\n","\n","The fundamental formula for Naive Bayes classification is derived from Bayes' theorem:\n","\n","##P(C|X) = [P(X|C) * P(C)] / P(X)\n","\n","###Where:\n","\n","P(C|X):The posterior probability of class C given the feature vector X. (What we want to calculate)\n","\n","P(X|C): The likelihood of observing feature vector X given class C.\n","\n","P(C): The prior probability of class C. (How likely is the class in general)\n","\n","P(X): The prior probability of observing feature vector X. (Usually ignored as it's a constant for all classes)"],"metadata":{"id":"G7uDX1myjhKg"}},{"cell_type":"markdown","source":["# Problem statement\n","\n","## Naive Bayes Classifier for Text Classification\n","(Assuming a set of documents that need to be classified,use the naive bayesian classifier model to perform this task.built-in-Java classes/API can be used to write the program.Calculate the accuracy,precision and recall for your datasets\n"],"metadata":{"id":"OcZERD1VqSdB"}},{"cell_type":"markdown","source":["# Implementation\n"],"metadata":{"id":"Zs4opM7mt7hy"}},{"cell_type":"code","source":["#Import the Necessary libraries\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from nltk.corpus import stopwords  # Import stopwords for optional removal\n","import string  # Import string for punctuation removal"],"metadata":{"id":"1TimgJ9t8znQ","executionInfo":{"status":"ok","timestamp":1720091181495,"user_tz":-330,"elapsed":41,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":171,"outputs":[]},{"cell_type":"code","source":["def preprocess_text(text):\n","  # Lowercase and remove punctuation\n","  text = text.lower().translate(str.maketrans('', '', string.punctuation))\n","  words = text.split()\n","\n","  # Optionally remove some stop words (consider reducing the number of stopwords removed)\n","  stop_words = stopwords.words('english')\n","  # words = [word for word in words if word not in stop_words]  # Uncomment for some stopword removal\n","\n","  # Join the words back into a string\n","  return ' '.join(words)  # Return a string instead of a list of words\n"],"metadata":{"id":"HtBCyUuP9yru","executionInfo":{"status":"ok","timestamp":1720091181495,"user_tz":-330,"elapsed":25,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":172,"outputs":[]},{"cell_type":"code","source":["#function called load_data that reads data from a CSV file and creates a list of Document objects. Let's break it down step by step:\n","def load_data(filename):\n","  data = pd.read_csv(filename)\n","  documents = []\n","  for index, row in data.iterrows():\n","    documents.append(Document(row[\"Text\"], row[\"Label\"]))\n","  return documents\n"],"metadata":{"id":"6WKhxIYN-AQZ","executionInfo":{"status":"ok","timestamp":1720091181496,"user_tz":-330,"elapsed":24,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":173,"outputs":[]},{"cell_type":"code","source":["class Document: #class defination\n","  def __init__(self, text, category):  #constructor method\n","    self.text = text #attribute assignment\n","    self.category = category"],"metadata":{"id":"G2AvzRvw-GAD","executionInfo":{"status":"ok","timestamp":1720091181496,"user_tz":-330,"elapsed":24,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":174,"outputs":[]},{"cell_type":"markdown","source":["# Train the model"],"metadata":{"id":"O7YqEh974eZt"}},{"cell_type":"code","source":["def train_model(documents):\n","  # Prepare data\n","  X = [preprocess_text(doc.text) for doc in documents]\n","  y = [doc.category for doc in documents]\n","\n","  # Feature extraction with TF-IDF\n","  vectorizer = TfidfVectorizer(min_df=1)  # Adjust min_df if necessary\n","  X_features = vectorizer.fit_transform(X)\n","\n","  # Train the Naive Bayes model\n","  model = MultinomialNB()\n","  model.fit(X_features, y)\n","\n","  return model, vectorizer"],"metadata":{"id":"TA_NAPwz-auG","executionInfo":{"status":"ok","timestamp":1720091181497,"user_tz":-330,"elapsed":25,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":175,"outputs":[]},{"cell_type":"markdown","source":["# to predict the category of a new document using a pre-trained model and a vectorizer."],"metadata":{"id":"3j7yRevgZaDh"}},{"cell_type":"code","source":["def predict_category(model, vectorizer, new_doc):\n","  # Preprocess new document\n","  new_doc_features = vectorizer.transform([preprocess_text(new_doc)])\n","\n","  # Predict category\n","  predicted_category = model.predict(new_doc_features)[0]\n","  return predicted_category"],"metadata":{"id":"M6RAbWJZZJTz","executionInfo":{"status":"ok","timestamp":1720091181497,"user_tz":-330,"elapsed":25,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":176,"outputs":[]},{"cell_type":"markdown","source":["# Evalute the model"],"metadata":{"id":"b-FTSD1mZsxL"}},{"cell_type":"code","source":["\n","def evaluate_model(model, vectorizer, test_data):\n","  # Prepare data\n","  X_test = [preprocess_text(doc.text) for doc in test_data]\n","  y_test = [doc.category for doc in test_data]\n","\n","  X_test_features = vectorizer.transform(X_test)\n","\n","  # Predict categories\n","  predicted_categories = model.predict(X_test_features)\n","\n","  # Calculate metrics\n","  accuracy = accuracy_score(y_test, predicted_categories)\n","  precision = precision_score(y_test, predicted_categories, average='weighted')\n","  recall = recall_score(y_test, predicted_categories, average='weighted')\n","\n","  return accuracy, precision, recall\n"],"metadata":{"id":"jSpmPywP-gX-","executionInfo":{"status":"ok","timestamp":1720091181497,"user_tz":-330,"elapsed":25,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["# Load data from CSV\n","filename = \"/content/dataset.csv\"  # Replace with your actual CSV file path\n","documents = load_data(filename)\n"],"metadata":{"id":"QG_8Vvbp4ylO","executionInfo":{"status":"ok","timestamp":1720091181498,"user_tz":-330,"elapsed":26,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":178,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","model, vectorizer = train_model(documents)\n"],"metadata":{"id":"BWkmUqal5HYj","executionInfo":{"status":"ok","timestamp":1720091181498,"user_tz":-330,"elapsed":26,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["\n","# New document to classify\n","new_doc = \"my heart is broken because my love is failure .\""],"metadata":{"id":"jUwpZgXa_VhC","executionInfo":{"status":"ok","timestamp":1720091181498,"user_tz":-330,"elapsed":26,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":180,"outputs":[]},{"cell_type":"code","source":["\n","# Predict the class\n","predicted_category = predict_category(model, vectorizer, new_doc)\n","print(\"Predicted class:\", predicted_category)\n","\n","# Split data into train and test (optional)\n","# You can split your data into training and testing sets for evaluation using libraries like scikit-learn's train_test_split\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ogw7X2qR_frB","executionInfo":{"status":"ok","timestamp":1720091181499,"user_tz":-330,"elapsed":27,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}},"outputId":"44e9bb16-04f8-4f26-c4bf-3ce8aa33d273"},"execution_count":181,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class: negative\n"]}]},{"cell_type":"code","source":["# Evaluate the model on test data (replace with your actual test data)\n","test_data = documents[:int(0.8 * len(documents))]  # Assuming 80% for training\n","accuracy, precision, recall = evaluate_model(model, vectorizer, test_data)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMlyTGguGi2U","executionInfo":{"status":"ok","timestamp":1720091181499,"user_tz":-330,"elapsed":27,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}},"outputId":"b6c06f81-3775-4fa1-fdd1-0c2c1c8bdfbb"},"execution_count":182,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9\n","Precision: 0.8166666666666668\n","Recall: 0.9\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AqR1vhG5Gm9S","executionInfo":{"status":"ok","timestamp":1720091181499,"user_tz":-330,"elapsed":27,"user":{"displayName":"Francy Pothuraju","userId":"04225123381959978702"}}},"execution_count":182,"outputs":[]}]}